1---
title: "Transit Segments"
author: "Max Czapanskiy"
date: "`r format(Sys.time(), '%d %B, %Y')`"
knit: (function(inputFile, encoding) { 
         out_dir <- '../analysis/reports';
         out_file <- file.path(dirname(inputFile), out_dir, 'TransitSegments.html');
         rmarkdown::render(inputFile,
                           encoding = encoding, 
                           output_file = out_file);
       })
output: html_document
---

```{r setup, message = FALSE}
knitr::opts_chunk$set(
	message = FALSE,
	warning = FALSE,
	cache = TRUE
)
library(dplyr)
library(lubridate)
library(zoo)
library(geosphere)
library(ggplot2)
library(knitr)
library(tidyr)
library(foreach)
library(doParallel)
library(iterators)
library(mosaic)
library(RSQLite)
library(data.table)
library(ggthemes)
library(grid)
library(forcats)

# dplyr connections
MHI_db <- src_sqlite('../data/MHI_GPS.sqlite')
metadata_db <- tbl(MHI_db, 'Metadata')
tidytracks_db <- tbl(MHI_db, 'TidyTracks')

POSIX.origin = ymd('1970-01-01', tz = 'UTC')
```

## Recap RST results
```{r RST_recap}
tracks <- tidytracks_db %>%
  # Join GPS type and subcolony code from metadata
  left_join(select(metadata_db, DeployID, GPS_type, SubColCode),
            by = 'DeployID') %>%
  # Filter to RFO @ KPNWR w/ e-obs tags
  filter(Species == 'RFBO',
         GPS_type == 'e-obs',
         SubColCode == 'KPC') %>%
  collect(n = Inf) 

med_tor <- median(tracks$Tortuosity, na.rm = TRUE)
tracks %>%
  filter(Tortuosity > 1, Tortuosity < 1.5) %>%
  ggplot(aes(x = Tortuosity)) + 
  geom_histogram(binwidth = 0.01, boundary = 0) +
  geom_vline(xintercept = med_tor, color = 'red') +
  labs(title = 'Median tortuosity is 1.05')

transit_spd <- tracks %>%
  filter(Tortuosity < med_tor,
         Speed > 1) %>%
  summarize(mean(Speed)) %>%
  as.numeric

ggplot(tracks, aes(x = Speed, fill = Tortuosity > med_tor)) + 
  geom_histogram(binwidth = 0.5) +
  xlim(0,20) +
  geom_vline(xintercept = transit_spd) +
  labs(x = 'Speed (m/s)',
       y = 'Count of Track Points',
       title = 'Mean Transit Speed') +
  theme(legend.position = 'None')

# What's the mean transit speed after classification?
tracks %>%
  filter(Behavior == 'transit') %>%
  summarize(mean(Speed))
```

## Identify Transit Segments
Transit segments are the basis of analysis for the flight cost model. 

Here we define a transit segment as the following:

* 20 minutes (i.e. 10 consecutive points)
* No gaps longer than 150% of the scheduled sampling rate (i.e. 3 minutes)
* Standard deviation of speed < 1.5m/s
* At least 9 of the 10 points are classified as transit by the RST algorithm (Torres et al. 2017)

Only single-day trips will be considered.

```{r segments}
# tracks: a data frame with the RFBO e-obs tracks from KPNWR
tracks <- tidytracks_db %>%
  # Join GPS type and subcolony code from metadata
  left_join(select(metadata_db, DeployID, GPS_type, SubColCode),
            by = 'DeployID') %>%
  # Filter to RFO @ KPNWR w/ e-obs tags
  filter(Species == 'RFBO',
         GPS_type == 'e-obs',
         SubColCode == 'KPC') %>%
  collect(n = Inf) %>%
  group_by(TripID) %>%
  # Filter out multiday and excessively short (< 15 points) trips
  filter((max(TimestampUTC) - min(TimestampUTC)) / 3600 < 24,
         n() >= 15) %>%
  ungroup %>%
  # Mutate time from numeric to datetime and set DeployID/TripID to factors
  mutate(TimestampUTC = as.POSIXct(TimestampUTC, origin = POSIX.origin, tz = 'UTC'),
         DeployID = factor(DeployID),
         TripID = factor(TripID))

# The following variables are parameters and helper functions for summarizing segments
# window: the number of consecutive points in a segment
# leadWindow: window - 1, i.e. the number of points to lead by to reach the end
# getLeg: a function for determining if a transit segment is inbound/outbound. All segments 
#   before the farthest point from the colony are outbound, those after are inbound.
# meanBear: calculates the mean bearing along the segment. Fits a linear regression to the 
#   coordinates and gets the bearing from (first longitude, first fitted latitude) to
#   (last longitude, last fitted latitude).
window <- 10
leadWindow <- window - 1
getLeg <- function(t, tmax) {
  if(t < tmax) 
    'Outbound'
  else
    'Inbound'
}
meanBear <- function(lonlat) {
  lon <- lonlat[,1]
  lat <- lonlat[,2]
  m <- lm(lat ~ lon)
  pLat <- predict(m)
  bearing(c(first(lon), first(pLat)), c(last(lon), last(pLat)))
}
rollapply2 <- function(...) {
  rollapply(..., fill = NA, partial = FALSE, align = 'left')
}

# segments0: ALL 10-point segments within tracks
segments0 <- tracks %>%
  arrange(TripID, TimestampUTC) %>%
  group_by(TripID) %>%
  mutate(Start = TimestampUTC,
         End = lead(TimestampUTC, leadWindow),
         DistToCol,
         # Leg is a categorical variable specifying if the segment is outbound or inbound
         maxD2Ctime = TimestampUTC[which.max(DistToCol)],
         Leg = rollapply2(TimestampUTC, window, getLeg, maxD2Ctime),
         # maxGap is the longest gap between rediscretized and original track points
         maxGap = rollapply2(PositionLag, window, max),
         # Mean and standard deviation of speed
         meanSpd = rollapply2(Speed, window, mean),
         sdSpd = rollapply2(Speed, window, sd),
         # Mean tortuosity
         meanTrt = rollapply2(Tortuosity, window, mean, na.rm = TRUE),
         # Number of points classified as transit
         nTransit = rollapply2(Behavior, window, function(b) sum(b == 'transit', na.rm = TRUE)),
         # Net displacement
         displacement = distGeo(cbind(Longitude, Latitude), cbind(lead(Longitude, leadWindow), lead(Latitude, leadWindow))),
         # Net bearing
         bearing = rollapply2(data.frame(Longitude, Latitude), window, meanBear, by.column = FALSE)) %>%
  select(DeployID, TripID, Longitude, Latitude, Start:bearing)

# segments: only the segments that satisfy transit criteria
segments <- segments0 %>%
  na.omit %>%
  filter(maxGap <= 180,
         sdSpd < 1.5,
         nTransit >= 9)

# Export tracks, segments0, and segments
write.csv(tracks, '../data/out/TransitSegments/Tracks.csv', row.names = FALSE)
write.csv(segments0, '../data/out/TransitSegments/Segments0.csv', row.names = FALSE)
write.csv(segments, '../data/out/TransitSegments/Segments.csv', row.names = FALSE)
save(tracks, segments0, segments, file = '../data/out/TransitSegments/Segments.RData')
```

```{r segmentSummary}
p <- 
print(p)
ggsave('../analysis/figures/Fig2b.png', p, width = 170 * 1/3, height = 125, units = 'mm', dpi = 300)

segments %>% 
  ggplot(aes(x = Start,
             y = DeployID)) +
  geom_point() +
  scale_x_datetime(date_breaks = '2 weeks',
                   date_labels = '%e %b') +
  labs(x = 'Segment Date',
       title = 'Temporal Distribution of Segments')

# Figure 2
p2a <- segments %>%
  ggplot(aes(x = as.Date(Start))) +
  stat_bin(aes(y = cumsum(..count..) / sum(..count..)), 
           binwidth = 2,
           geom = 'step') +
  geom_vline(xintercept = as.numeric(ymd('2016-07-11')), linetype = 'dashed') +
  scale_x_date(date_breaks = '2 weeks',
               date_labels = '%e %b') +
  labs(x = NULL,
       y = 'Fraction of Segments',
       title = 'Cumulative Temporal Distribution of Segments') +
  theme_few()
print(p2a)
inset_vp <- viewport(width = 0.47, height = 0.61, x = 0.5, y = 0.07, just = c(0,0))
p2b <- segments %>% 
  ggplot(aes(x = fct_rev(fct_infreq(DeployID)))) +
  geom_bar() +
  labs(x = 'Bird ID',
       y = NULL,
       title = 'Transit Segments Per Bird') +
  scale_y_continuous(breaks = seq(0, 2500, by = 500)) +
  coord_flip() +
  theme_few(base_size = 10) +
  theme(legend.position = 'bottom')
print(p2b, vp = inset_vp)
# Movement Ecology 170mm fig width
png('../analysis/figures/Fig2.png', width = 170, height = 125, units = 'mm', res = 300)
print(p2a)
print(p2b, vp = inset_vp)
dev.off()
```

Transit segments are unevenly distributed among individuals due to differences in deployment duration. At the low end, 1147 and 1156 both have ~150-200 segments, while 1153 and 1159 have around 2,700. Temporally, there is an inflection point around the middle of July. Looking at these plots, I suggest excluding deployments 1147, 1155, and 1156 as questionable quality and set a temporal cut off at July 17th (50 days after deployment) to keep data internally consistent.

Using the DeployID and date restrictions, we find the following:

```{r segPerTrip}
# Exclusion parameters
excludeDID <- c(1147, 1155, 1156)
cutoffDate <- ymd('2016-07-18', tz = 'UTC')
validSegments <- segments %>%
  ungroup %>%
  filter(!(DeployID %in% excludeDID),
         Start < cutoffDate) %>%
  mutate(SegmentID = seq(DeployID))

# Save validSegments to RData file
save(excludeDID, cutoffDate, validSegments, file = '../data/out/TransitSegments/ValidSegments.RData')

# Outbound and inbound segments per trip
segPerTrip <- validSegments %>%
  group_by(TripID, Leg) %>%
  summarize(N = n()) %>%
  ungroup %>%
  spread(Leg, N)
  
# Summary table: out only, in only, both segments
segPerTrip %>%
  summarize(OutOnly = sum(!is.na(Outbound) & is.na(Inbound)),
            InOnly = sum(is.na(Outbound) & !is.na(Inbound)),
            OutIn = sum(!is.na(Outbound) & !is.na(Inbound)))

# Trips with out and in by bird
legLabels <- c('Inbound only', 'Outbound only', 'Outbound and Inbound')
segPerTrip %>%
  mutate(DeployID = factor(substr(TripID, 1, 4))) %>%
  group_by(DeployID) %>%
  summarize(OutIn = sum(!is.na(Outbound) & !is.na(Inbound)),
            OutOnly = sum(!is.na(Outbound) & is.na(Inbound)),
            InOnly = sum(is.na(Outbound) & !is.na(Inbound))) %>%
  gather(Legs, Count, OutIn:InOnly) %>%
  mutate(Legs = factor(Legs, 
                       levels = c('InOnly', 'OutOnly', 'OutIn'),
                       labels = legLabels)) %>%
  ggplot(aes(x = DeployID,
             y = Count,
             fill = Legs)) +
  geom_bar(stat = 'identity') +
  labs(y = 'Count of Trips',
       title = 'Trips by Segment Legs Across Birds') +
  theme(legend.position = 'bottom')
```

 * 42 trips only have outbound segments
 * 96 trips only have inbound segments
 * 263 trips have both segments
 * Tracked birds had between 12 and 28 trips with both outbound and inbound segments
 
## Transit Acceleration
Pick out the acceleration data from the transit segments to plot raw values and examine flight behavior patterns. Calibrate the acceleration data to m/s^2 and separate the static from dynamic acceleration. The results are written to a table called SegmentACC.

```{r transitAcc, eval = FALSE}
# Acceleration metadata
accMeta <- metadata_db %>%
  # Filter to the e-obs tagged RFBO from KPNWR
  filter(Species == 'RFBO',
         GPS_type == 'e-obs',
         SubColCode == 'KPC') %>%
  # Select the GPS_ID (for finding the acceleration data file)
  select(DeployID, GPS_ID) %>%
  collect %>% 
  mutate(GPS_ID = as.integer(GPS_ID),
         DeployID = factor(DeployID)) %>%
  # Join the calibration constants
  left_join(read.csv('../data/calib_const.csv'),
            by = c('GPS_ID' = 'TagID')) %>%
  # Keep only the deployments with valid segments
  semi_join(validSegments, by = 'DeployID')

# Segments joined with acceleration metadata
segmentsACCmeta <- validSegments %>%
  left_join(accMeta, by = 'DeployID') %>%
  as.data.frame %>%
  arrange(DeployID, TripID)

# Acceleration data for each segment
# Written to MHI_db because acceleration data is too big to keep in memory
# Process acceleration data by deployment and segment
accelerationProcessing <- foreach(accMetaRow = iter(accMeta, by = 'row'),
                                  .combine = rbind) %do% {
  cat(sprintf('Beginning DeployID %s\n', accMetaRow$DeployID))
  # Load acceleration file
  acc.file <- sprintf('../data/ClippedACC/%s.csv', accMetaRow$GPS_ID)
  acc.data <- read.csv(acc.file, stringsAsFactors = FALSE) %>%
    mutate(TimestampUTC = as.POSIXct(timestamp, format = '%Y-%m-%d %H:%M:%OS', tz = 'UTC'),
           BurstID = row_number()) %>%
    select(TimestampUTC, BurstID,
           acc.raw = eobs.accelerations.raw, 
           acc.freq = eobs.acceleration.sampling.frequency.per.axis)
  # Acceleration sampling frequency (20hz)
  acc.freq <- acc.data$acc.freq[1]
  
  # Gather the segments from the deployment specified in accMetaRow
  taskList <- filter(segmentsACCmeta,
                     DeployID == accMetaRow$DeployID)
  
  # Process acceleration data for each segment
  deployACC <- foreach(seg = iter(taskList, by = 'row'),
                       .combine = rbind) %do% {
    
    cat(sprintf('Beginning DeployID %s, SegmentID %i\n', accMetaRow$DeployID, seg$SegmentID))
    # Filter temporally to acceleration data from segment
    segAccRaw <- acc.data %>%
      filter(TimestampUTC >= seg$Start, TimestampUTC <= seg$End)
    if(nrow(segAccRaw) == 0)
      return(data.frame(DeployID = seg$DeployID,
                        SegmentID = seg$SegmentID,
                        Processed = FALSE,
                        Issue = 'NoRawData'))
    
    # Process each burst by splitting the raw acceleration and calibrating
    # Write to a SQLite table with columns: 
    #   DeployID, SegmentID, BurstID, 
    #   ACCTimestampUTC, X0, Y0, Z0, X, Y, Z,
    #   StaticX, StaticY, StaticZ, DynX, DynY, DynZ
    segAccProcessed <- foreach(burst = iter(segAccRaw, by = 'row'),
                               .combine = rbind) %do% {
      # Verify acceleration data exists
      if(nchar(burst$acc.raw) == 0)
        return(data.frame())
                                 
      # Acceleration data in long format
      longACC <- strsplit(burst$acc.raw, ' ') %>%
        unlist %>%
        as.numeric %>%
        matrix(ncol = 3, byrow = TRUE, dimnames = list(NULL, c('X0', 'Y0', 'Z0'))) %>%
        as.data.frame
      
      # Calibrate acceleration
      mutate(longACC,
             DeployID = seg$DeployID,
             SegmentID = seg$SegmentID,
             BurstID = burst$BurstID,
             ACCTimestampUTC = burst$TimestampUTC + (seq_along(X0) - 1) / acc.freq,
             X = seg$bX + seg$mX * X0,
             Y = seg$bY + seg$mY * Y0,
             Z = seg$bZ + seg$mZ * Z0,
             StaticX = runmed(X, acc.freq * 2 - 1, endrule = 'constant'),
             StaticY = runmed(Y, acc.freq * 2 - 1, endrule = 'constant'),
             StaticZ = runmed(Z, acc.freq * 2 - 1, endrule = 'constant'),
             DynX = X - StaticX,
             DynY = Y - StaticY,
             DynZ = Z - StaticZ,
             ODBA = abs(DynX) + abs(DynY) + abs(DynZ))
    }
    
    # If the segment has acceleration data, add it to the SQLite table
    if(nrow(segAccProcessed) > 0) {
      dbWriteTable(MHI_db$con, 'SegmentACC', segAccProcessed,
                   overwrite = FALSE, append = TRUE)
      data.frame(DeployID = seg$DeployID,
                 SegmentID = seg$SegmentID,
                 Processed = TRUE,
                 Issue = '')
    } else {
      data.frame(DeployID = seg$DeployID,
                 SegmentID = seg$SegmentID,
                 Processed = FALSE,
                 Issue = 'NoProcessedData')
    }
    cat(sprintf('Finished DeployID %s, SegmentID %i\n', accMetaRow$DeployID, seg$SegmentID))
  }
  cat(sprintf('Finished DeployID %s\n', accMetaRow$DeployID))
}

accelerationProcessing %>%
  group_by(DeployID, Processed, Issue) %>%
  summarize(N = n())
```
